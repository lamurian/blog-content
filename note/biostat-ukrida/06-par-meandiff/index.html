---
author: lam
title: "Parametric: Mean in Two Groups"
weight: 6
description: >

  When we have a normally-distributed data, parameters $\mu$ and $\sigma$ from
  our PDF can completely explain the behaviour seen in our sample. With $\mu$
  represents the central tendency and $\sigma$ the spread, we can directly
  compare similarly distributed samples. Often, we need to confirm how much our
  average value differs from other observations. In doing so, we are facing a
  mean difference problem in our venture of statistics. This lecture will help
  us proving mean differences in one-sample and two-sample problems.

summary: >

  When we have a normally-distributed data, parameters $\mu$ and $\sigma$ from
  our PDF can completely explain the behaviour seen in our sample. With $\mu$
  represents the central tendency and $\sigma$ the spread, we can directly
  compare similarly distributed samples. Often, we need to confirm how much our
  average value differs from other observations. In doing so, we are facing a
  mean difference problem in our venture of statistics. This lecture will help
  us proving mean differences in one-sample and two-sample problems.

date: 2020-10-15
categories: ["statistics", "ukrida"]
tags: ["R", "hypothesis"]
slug: 06-par-meandiff
csl: ../harvard.csl
bibliography: ../ref.bib
draft: false
---



<p><a href="https://lamurian.rbind.io/note/biostat-ukrida/06-par-meandiff/slide">Slide</a></p>
<p>When we obtain a normally-distributed data, parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> from
our PDF can completely explain the behaviour seen in our sample. With <span class="math inline">\(\mu\)</span>
represents the central tendency and <span class="math inline">\(\sigma\)</span> the spread, we can directly
compare similarly distributed samples. Often, we need to confirm how much our
average value differs from other observations. In doing so, we are facing a
mean difference problem in our venture of statistics. This lecture will help us
proving mean differences in one-sample and two-sample problems.</p>
<div id="mean-difference" class="section level1">
<h1>Mean Difference</h1>
<p>We may have a vivid recollection on previous lectures of data distribution and
the Central Limit Theorem (CLT). For any data following a normal distribution,
centering and scaling according to its <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> results in a
standardized normal distribution, i.e. a Z-distribution.</p>
<p><span class="math display">\[\frac{x - \bar{x}}{s} \sim N(0, 1) \tag{1}\]</span></p>
<p>For any given distribution, the mean of such a sample will undergo a
convergence of random variable into a normal distribution with parameters of
<span class="math inline">\(\mu\)</span> and <span class="math inline">\(\frac{\sigma}{\sqrt{n}}\)</span>.</p>
<p><span class="math display">\[\bar{X} \xrightarrow{d} N(\mu, \frac{\sigma}{\sqrt{n}}) \tag{2}\]</span></p>
<p>With known <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>, we can make a direct comparison between our data
and the population. However, how if we do not know the parameter <span class="math inline">\(\mu\)</span>? We can
make a close estimate using its statistics, <span class="math inline">\(\bar{x}\)</span>. A mean difference is
simply a result of subtracting sampled mean from the hypothesized parameter,
which corresponds to <span class="math inline">\(\bar{x} - \mu_0\)</span>. However, our sample bounds to have
error, either a systematic or unsystematic (random) ones. An adjustment to such
problems requires us to divide our measures into the standard error. Obtained
quotient is our statistics of interest, which will follow a Z-distribution.</p>
<p><span class="math display">\[\begin{align}
SE &amp;= \frac{\sigma}{\sqrt{n}} \tag{Standard Error} \\
\\
z  &amp;= \frac{\bar{x} - \mu_0}{SE} \\
   &amp;= \frac{\bar{x} - \mu_0}{^{\sigma}/\tiny{\sqrt{n}}} \tag{One-sample Test}
\end{align}\]</span></p>
<p>Having our statistics as an element of Z-distribution, we can compute the
p-value by looking at the probability of our statistical value. As always, we
first need to initiate the <strong>significant level</strong> <span class="math inline">\(\alpha\)</span> so we can measure where
our statistics is located in relation to the <strong>significant value</strong>
<span class="math inline">\(x: P(X \leqslant x\ |\ 0, 1)=\alpha\)</span>. We regard this approach as a Z-Test, where the
p-value represents probabilities of <span class="math inline">\(P(Z = z\ |\ 0, 1)\)</span>.</p>
<p>We shall consider the following scenario as an example:</p>
<blockquote>
<p>In a population of third-year electrical engineering students, we know the
<strong>average final score</strong> of a particular course is <strong>70</strong>. In measuring
students’ comprehension, UKRIDA has established a standardized examination with
a <strong>standard deviation</strong> of <strong>10</strong>. We are interested to see whether
students registered to this year course have different average, where 18
students averagely scored 75 on the final exam.</p>
</blockquote>
<p>Then, we need to formulate our hypotheses:</p>
<p><span class="math display">\[\begin{align}
H_0 &amp;: \bar{x} = \mu_0 \\
H_a &amp;: \bar{x} \neq \mu_0
\end{align}\]</span></p>
<p>Followed by computing the <span class="math inline">\(z\)</span> statistics:</p>
<p><span class="math display">\[\begin{align}
SE &amp;= \frac{10}{\sqrt{18}} &amp;= 2.36 \\
z  &amp;= \frac{75 - 70}{2.36} &amp;= 2.12
\end{align}\]</span></p>
<p>Where does <span class="math inline">\(z\)</span> located in Z-distribution?</p>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/z.dist1-1.png" width="100%" /></p>
<p>Assigning our significance value on both tails results in:</p>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/z.dist2-1.png" width="100%" /></p>
<p>Since our <span class="math inline">\(H_a\)</span> assumes non-equality, we can compute the p-value according to
two-tailed test procedures. First we need to find the cumulative probability of
<span class="math inline">\(z\)</span> which satisfies:</p>
<p><span class="math display">\[P(Z \leqslant 2.12\ |\ \mu,\sigma): Z \sim N(0, 1)\]</span></p>
<p>Then we have to subtract <span class="math inline">\(P(Z=z)\)</span> from 1 and multiply the difference by 2 to
obtain the two-tailed p-value.</p>
<pre class="r"><code>2 * {1 - pnorm(2.12, 0, 1)}</code></pre>
<pre><code>## [1] 0.034</code></pre>
<p>So far, we understand that Z-test requires the sample to follow a normal
distribution. Before conducting any formal test, it is imperative to ascertain
the sampled distribution, i.e. using a goodness of fit or normality test. We do
not need to know the parameter <span class="math inline">\(\mu\)</span> because we can hypothesize the value.
However, we <em>need</em> the parameter <span class="math inline">\(\sigma\)</span> to correctly compute <span class="math inline">\(z\)</span>. It is
becoming quite problematic when we do not know the value of <span class="math inline">\(\sigma\)</span>, of which
we often don’t! In such a case, we need to consider using a T-distribution
instead.</p>
</div>
<div id="students-t-distribution" class="section level1">
<h1>Student’s T-Distribution</h1>
<p>Student’s T-distribution only depends on 1 parameter, degree of freedom <span class="math inline">\(\nu\)</span>.
Mathematically, T-distribution has the following notation: <span class="math inline">\(X \sim t_{\nu}\)</span>.
The T-distribution is pivotal to compute statistics in mean difference of a
normally-distributed data. Degree of freedom <span class="math inline">\(\nu\)</span> in T-distribution is simply
<span class="math inline">\(n - 1\)</span>, where <span class="math inline">\(n\)</span> represents the total number of sample.</p>
<p><span class="math display">\[\begin{align}
Let\ &amp; X \sim t_\nu \tag{Notation} \\
P(X=x) &amp;= \frac{\Gamma \big( \frac{\nu+1}{2} \big)}{\sqrt{\nu \pi}\ \Gamma \big( \frac{\nu}{2} \big)} \bigg( 1 + \frac{x^2}{\nu} \bigg) \tag{PDF} \\
\nu &amp;= n - 1 \\
\\
Let\ &amp; T \sim t_\nu \\
T &amp;= Z \sqrt{\frac{\nu}{V}} \tag{Relationship}
\end{align}\]</span></p>
<p>Aside from its relationship with Z-distribution, T-distribution also
independently relates to the <span class="math inline">\(chi^2\)</span> distribution, where they share the same
<span class="math inline">\(\nu\)</span> degree of freedom.</p>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/t.dist-1.png" width="100%" /></p>
</div>
<div id="one-sample-t-test" class="section level1">
<h1>One Sample T-Test</h1>
<p>One sample T-test is analogous to the Z-test, where we use it when we could not
ascertain the <span class="math inline">\(\sigma\)</span>. In place of <span class="math inline">\(\sigma\)</span>, T-test use <span class="math inline">\(s\)</span> as an estimate to
the population parameter. By adapting the <span class="math inline">\(z\)</span> statistics equation, we can
compute <span class="math inline">\(t\)</span> statistics as follow:</p>
<p><span class="math display">\[t = \frac{\bar{x}-\mu}{^s \big/ \tiny{\sqrt{n}}}\]</span></p>
<p>As an example, we shall generate an array of random numbers following a normal
distribution where <span class="math inline">\(X \sim N(120, 20)\)</span>.</p>
<pre class="r"><code>set.seed(1)
x &lt;- rnorm(20, mean=120, sd=20)</code></pre>
<p>First, we do some basic exploratory analysis by finding the central tendency
and spread.</p>
<pre class="r"><code>summary(x)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    75.7   112.3   127.2   123.8   135.2   151.9</code></pre>
<pre class="r"><code>sd(x)</code></pre>
<pre><code>## [1] 18.3</code></pre>
<p>We let <span class="math inline">\(x \sim N(120, 20)\)</span>, yet our <span class="math inline">\(\bar{x}\)</span> is 123.81 with an <span class="math inline">\(s\)</span> of <code>r sd(s)</code> and a <span class="math inline">\(\nu\)</span> of 19. Does our statistics differ from the parameter
<span class="math inline">\(\mu=120\)</span>? We can further formulate our question into hypotheses:</p>
<p><span class="math display">\[\begin{align}
H_0 &amp;: \bar{x} = 120 \\
H_a &amp;: \bar{x} \neq 120
\end{align}\]</span></p>
<p>Then we can determine the <span class="math inline">\(t\)</span> statistics:</p>
<pre class="r"><code>t &lt;- {{mean(x) - 120} / {sd(x) / sqrt(20)}} %T&gt;% print()</code></pre>
<pre><code>## [1] 0.933</code></pre>
<p>Then we shall locate <span class="math inline">\(t\)</span> statistics into its distribution of <span class="math inline">\(t_{19}\)</span>:</p>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/plt.one.sample1-1.png" width="100%" /></p>
<p>Then we can compute the p-value for a one-tailed test:</p>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/plt.one.sample2-1.png" width="100%" /></p>
<pre class="r"><code>1 - pt(t, df=19)</code></pre>
<pre><code>## [1] 0.181</code></pre>
<p>Also the p-value for a two-tailed test:</p>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/plt.one.sample3-1.png" width="100%" /></p>
<pre class="r"><code>2 * {1 - pt(t, df=19)}</code></pre>
<pre><code>## [1] 0.363</code></pre>
<p>How does our calculation compare to the built-in function in <code>R</code>?</p>
<pre class="r"><code>t.test(x, mu=120)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  x
## t = 0.9, df = 19, p-value = 0.4
## alternative hypothesis: true mean is not equal to 120
## 95 percent confidence interval:
##  115 132
## sample estimates:
## mean of x 
##       124</code></pre>
<p>At this point, we may have realised <code>R</code> only prints the rounded value for
acquired computation. If we are interested to see the actual value, we may save
our test result as an object, then directly call the specific result. In
following demonstration, we shall save the T-test and obtain its p-value.</p>
<pre class="r"><code>t.result &lt;- t.test(x, mu=120)
t.result$p.value</code></pre>
<pre><code>## [1] 0.363</code></pre>
<p>Comparing our computation and the result acquired from <code>R</code> built-in function,
we failed to reject our <span class="math inline">\(H_0\)</span>, so we conclude <span class="math inline">\(\bar{x}=\mu_0=120\)</span>.</p>
</div>
<div id="unpaired-t-test" class="section level1">
<h1>Unpaired T-Test</h1>
<p>When we two samples, we can compare the central tendency of both samples by
computing the mean difference. If both data follow a normal distribution, we
are conducting a two-sample T-test. As in previous examples, unpaired T-Test
(or rather, T-Test in general) assumes normality. Moreover, there are further
assumptions when conducting T-test, resulting in two distinctive types of said
test, i.e. a Student’s and Welch’s approach. T-test is arguably robust in
non-normally distributed data to a certain degree, where skewedness and
outliers highly influence its robustness. The problem with robustness is the
way we properly evaluate how T-test may provide a correct inference in the
event of having non-normal data. A few simulations have demonstrated how T-test
robust against <span class="math inline">\(\chi^2\)</span> distribution with a <em>specific</em> range of <span class="math inline">\(\nu\)</span>. However,
when we have a real-world data, we often do not know their underlying
parameters. In such cases, it is safe to follow normality assumption to avoid
type-I error inflations. To test mean difference between two samples, we
formulate following hypotheses:</p>
<p><span class="math display">\[\begin{align}
H_0 &amp;: \bar{x}_1 - \bar{x}_2 = d \\
H_a &amp;: \bar{x}_1 - \bar{x}_2 \neq d \\
d &amp;= \mu_1 - \mu_2 = 0
\end{align}\]</span></p>
<p>As outlined above, our hypotheses depends on the value of <span class="math inline">\(d\)</span>, which defaulted
to <span class="math inline">\(0\)</span>. In some rare occasion, we may apply a different value of <span class="math inline">\(d\)</span>, but for now
we will stick with <span class="math inline">\(d=0\)</span>.</p>
<div id="students-t-test" class="section level2">
<h2>Student’s T-Test</h2>
<p>Student’s approach in T-test is a test with pooled variance. We may conduct
this test when we know that variances in both samples are comparably similar.
We denote similarity as a homogeneity of variance, which we can prove using the
Levene’s test.</p>
<p><span class="math display">\[\begin{align}
t &amp;= \frac{\bar{x}_1 - \bar{x}_2 - d}{s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}} \tag{Statistics} \\
s_p &amp;= \sqrt{\frac{(n_1 - 1) s_1^2 + (n_2 - 1) s_2^2}{\nu}} \tag{Pooled variance} \\
\nu &amp;= n_1 + n_2 - 2 \tag{Degree of freedom}
\end{align}\]</span></p>
<p>However, if our data fail to fulfill homogeneity of variance assumption, we
shall appropriately use a Welch’s T-test.</p>
</div>
<div id="welchs-t-test" class="section level2">
<h2>Welch’s T-Test</h2>
<p>Welch’s approach still assume normality, but give more leniency to equality of
variance. As a result, Welch modified the equation to compute the <span class="math inline">\(t\)</span>
statistics, where we may find:</p>
<p><span class="math display">\[\begin{align}
t &amp;= \frac{\bar{x}_1 - \bar{x}_2 - d} {\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}} \tag{Statistics} \\
\nu &amp;= \frac{(n_1-1)(n_2-1)}{(n_2-1)C^2 + (1-C^2)(n_1-1)} \tag{Degree of freedom} \\
\\
C &amp;= \frac{\frac{s_1^2}{n_1}}{\frac{s_1^2}{n_1} \frac{s_2^2}{n_2}}
\end{align}\]</span></p>
<p>Compared to Student’s T-test, Welch’s provide a different measure of <span class="math inline">\(\nu\)</span> to
adjust for differences in sample variances. As an example, we may consider
following situation:</p>
<blockquote>
<p>Suppose we are collecting data on body height. Our population of interest will
be students registered in UKRIDA, where we categorize sex as female and male.
We acquire a normally distributed data from both sexes, where:</p>
<ul>
<li><span class="math inline">\(female \sim N(155, 15)\)</span></li>
<li><span class="math inline">\(male \sim N(170, 12)\)</span></li>
</ul>
<p>We have a sample of 25 females and 30 males, and would like conduct a
hypothesis test on mean difference.</p>
</blockquote>
<pre class="r"><code>set.seed(5)
tbl &lt;- data.frame(
    &quot;height&quot; = c(rnorm(30, 170, 8), rnorm(25, 155, 16)),
    &quot;sex&quot; = c(rep(&quot;male&quot;, 30), rep(&quot;female&quot;, 25))
)

tapply(tbl$height, tbl$sex, summary)</code></pre>
<pre><code>## $female
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##     123     146     154     158     173     190 
## 
## $male
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##     152     165     168     170     177     184</code></pre>
<pre class="r"><code>tapply(tbl$height, tbl$sex, sd)</code></pre>
<pre><code>## female   male 
##  17.98   7.93</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/two.sample.t2-1.png" width="100%" /></p>
<p>Do both groups in our sample follow a normal distribution?</p>
<pre class="r"><code>tapply(tbl$height, tbl$sex, shapiro.test)</code></pre>
<pre><code>## $female
## 
##  Shapiro-Wilk normality test
## 
## data:  X[[i]]
## W = 1, p-value = 0.7
## 
## 
## $male
## 
##  Shapiro-Wilk normality test
## 
## data:  X[[i]]
## W = 1, p-value = 0.2</code></pre>
<p>Considering both p-values being <span class="math inline">\(\geqslant 0.05\)</span> in Shapiro-Wilk test, we can
ascertain their normality. We then tested for homogeneity of variance using
Lavene’s test:</p>
<pre class="r"><code>car::leveneTest(tbl$height ~ tbl$sex)</code></pre>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = median)
##       Df F value  Pr(&gt;F)    
## group  1    14.3 0.00039 ***
##       53                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Interpreting a low p-value, we can conclude variances in both groups are not
equal to one another. In this case, we will follow Welch’s method.</p>
<pre class="r"><code>t.test(height ~ sex, data=tbl, var.equal=FALSE)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  height by sex
## t = -3, df = 32, p-value = 0.004
## alternative hypothesis: true difference in means between group female and group male is not equal to 0
## 95 percent confidence interval:
##  -19.87  -4.07
## sample estimates:
## mean in group female   mean in group male 
##                  158                  170</code></pre>
<p>Just for curiosity sake, we may want to try Student’s method as well and see
how it is different from Welch’s:</p>
<pre class="r"><code>t.test(height ~ sex, data=tbl, var.equal=TRUE)</code></pre>
<pre><code>## 
##  Two Sample t-test
## 
## data:  height by sex
## t = -3, df = 53, p-value = 0.002
## alternative hypothesis: true difference in means between group female and group male is not equal to 0
## 95 percent confidence interval:
##  -19.27  -4.67
## sample estimates:
## mean in group female   mean in group male 
##                  158                  170</code></pre>
<p>The Student’s T-test reported a lower p-value compared to Welch’s T-test
when we have unequal variance. A low p-value is not a bad sign per se, but we
need to be wary when we violated required assumptions. A low p-value may
indicate an inflation in statistical error. After conducting our test, we can
summarize our findings by visualizing them.</p>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/two.sample.t7-1.png" width="100%" /></p>
<p>Visualizing our results is important when conducting a statistical inference,
since it gives the reader a clearer representation on what we observed in our
data. Both figures give similar information, yet conveyed in different
fashions.</p>
</div>
</div>
<div id="paired-t-test" class="section level1">
<h1>Paired T-Test</h1>
<p>The equation in unpaired T-test implicitly imply independence of each data
point, where we could not correctly infer a paired data. We may consider using
a paired T-test when we have following situations:</p>
<ul>
<li>Difference between multiple measurements</li>
<li>Probability events where each instance influence another</li>
</ul>
<p>In measuring mean differences between paired data, first we need to reduce its
complexity. Suppose <span class="math inline">\(\mu_1\)</span> and <span class="math inline">\(\mu_2\)</span> represent measurement in <span class="math inline">\(t_1\)</span> and
<span class="math inline">\(t_2\)</span>. Both measures represent same subject (within comparison). We can calculate
the difference between both samples:</p>
<p><span class="math display">\[\mu_d = \mu_1 - \mu_2\]</span></p>
<p>Then, we only needed to take into account one-sample difference, where we
hypothesize:</p>
<p><span class="math display">\[\begin{align}
H_0 &amp;: \mu_d = 0 \\
H_a &amp;: \mu_d \neq 0
\end{align}\]</span></p>
<p>Does it seem familiar? Because it is! By reducing the complexity, we can infer
differences in paired data using a one-sample T-test to <span class="math inline">\(mu_d\)</span>. Following
example will help us visualizing the concept:</p>
<blockquote>
<p>In the current investigation, we are looking for the effect of a certain
anti-hipertensive drug. First we measure the blood pressure baseline, then
prescribe the drug to all subjects. Then, we re-measure the blood pressure
after one month. Each subject has a unique identifier, so we can specify mean
differences within paired samples. Suppose we have the following scenario in 30
sampled subjects:</p>
<ul>
<li><span class="math inline">\(X_1 \sim N(140, 12)\)</span></li>
<li><span class="math inline">\(X_2 \sim N(130, 17)\)</span></li>
</ul>
</blockquote>
<p>We then set our hypotheses:</p>
<p><span class="math display">\[\begin{align}
H_0 &amp;: \bar{x}_d = 0 \\
H_a &amp;: \bar{x}_d \neq 0
\end{align}\]</span></p>
<pre class="r"><code>set.seed(1)
tbl &lt;- data.frame(
    &quot;bp&quot; = c(rnorm(30, 140, 12), rnorm(30, 133, 17)),
    &quot;time&quot; = c(rep(&quot;Before&quot;, 30), rep(&quot;After&quot;, 30)) %&gt;%
        factor(levels=c(&quot;Before&quot;, &quot;After&quot;))
)

# Measure the mean of mean difference
md &lt;- with(tbl, bp[time==&quot;Before&quot;] - bp[time==&quot;After&quot;])

# Calculate t-statistics
t &lt;- {mean(md)} / {sd(md) / sqrt(30)} %T&gt;% print()</code></pre>
<pre><code>## [1] 3.12</code></pre>
<pre class="r"><code># Obtain p-value for a two-sided test
2 * {1 - pt(t, df=29)}</code></pre>
<pre><code>## [1] 0.076</code></pre>
<pre class="r"><code># Comparison to built-in one-sample T-Test
t.test(md, mu=0)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  md
## t = 2, df = 29, p-value = 0.08
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  -0.64 12.10
## sample estimates:
## mean of x 
##      5.73</code></pre>
<pre class="r"><code># Comparison to built-in paired T-Test
t.test(bp ~ time, data=tbl, paired=TRUE)</code></pre>
<pre><code>## 
##  Paired t-test
## 
## data:  bp by time
## t = 2, df = 29, p-value = 0.08
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.64 12.10
## sample estimates:
## mean of the differences 
##                    5.73</code></pre>
<div id="choosing-an-appropriate-test" class="section level2">
<h2>Choosing an Appropriate Test</h2>
<p>All tests explained in this post assume data normality, both for T-test and
Z-test. As a general rule of thumb, we may use following conventions:</p>
<ul>
<li>One-sample test:
<ul>
<li>Known <span class="math inline">\(\sigma \to\)</span> use Z-Test</li>
<li>Unknown <span class="math inline">\(\sigma \to\)</span> use one-sample T-Test</li>
</ul></li>
<li>Two-sample test <span class="math inline">\(\to\)</span> do Levene’s test
<ul>
<li>Equal variance: Student’s method (pooled variance)</li>
<li>Unequal variance: Welch’s method</li>
</ul></li>
<li>Paired T-Test: Basically one-sample T-Test on sampled differences</li>
</ul>
</div>
</div>
<div id="effect-size" class="section level1">
<h1>Effect Size</h1>
<p>The previous lecture on sample size equation served as a brief introduction on
statistical power, which presented us a new concept of effect size. There are
two related concepts to effect size and statistical power, <em>viz.</em> sample size
<span class="math inline">\(n\)</span> and significance level <span class="math inline">\(\alpha\)</span>. Effect size calculation varies on the type
of data we consider and how we conduct our formal test. In this section, we
will focus on measuring effect size in a mean difference between two groups
using Cohen’s distance <span class="math inline">\(d\)</span>.</p>
<p><span class="math display">\[\begin{align}
d &amp;= \frac{\bar{x}_1 - \bar{x}_2}{s_p} \tag{Cohen&#39;s D} \\
s_p &amp;= \sqrt{\frac{(s_1^2 + s_2^2)}{2}} \tag{Pooled SD}
\end{align}\]</span></p>
<p>As an example, we will re-use previous scenario:</p>
<pre class="r"><code>set.seed(1)
tbl &lt;- data.frame(
    &quot;bp&quot; = c(rnorm(30, 140, 12), rnorm(30, 133, 17)),
    &quot;time&quot; = c(rep(&quot;Before&quot;, 30), rep(&quot;After&quot;, 30)) %&gt;%
        factor(levels=c(&quot;Before&quot;, &quot;After&quot;))
)

# Measure the mean of mean difference
md &lt;- with(tbl, bp[time==&quot;Before&quot;] - bp[time==&quot;After&quot;])

# Calculate t-statistics
t &lt;- {mean(md)} / {sd(md) / sqrt(30)} %T&gt;% print()</code></pre>
<pre><code>## [1] 3.12</code></pre>
<pre class="r"><code># Obtain p-value for a two-sided test
2 * {1 - pt(t, df=29)}</code></pre>
<pre><code>## [1] 0.076</code></pre>
<p>We will calculate <span class="math inline">\(d\)</span> by issuing following command in <code>R</code>. Beware though,
different method of computing also exists as we can be more flexible in
expressing our code. I prefer this method because it clearly explains what we
do at the expense of the need to understand <code>apply</code> family of functions in <code>R</code>,
which is a good thing to know if you were to learn <code>R</code> (and I hope you will!)</p>
<pre class="r"><code># Calculate pooled standard deviation
sp &lt;- sqrt({with(tbl,
    tapply(bp, time, var, simplify=FALSE)) %&gt;% {do.call(add, .)}
} / 2) %T&gt;% print()</code></pre>
<pre><code>## [1] 12.4</code></pre>
<pre class="r"><code># Measure Cohen&#39;s distance
{with(tbl,
    tapply(bp, time, mean, simplify=FALSE)) %&gt;% {do.call(subtract, .)}
} / sp</code></pre>
<pre><code>## [1] 0.464</code></pre>
<p>As a comparison, we can also compute <span class="math inline">\(d\)</span> using the <code>psych</code> package.</p>
<pre class="r"><code># Calculate power using the `psych` package
d &lt;- psych::cohen.d(tbl ~ time) %T&gt;% print()</code></pre>
<pre><code>## Call: psych::cohen.d(x = tbl ~ time)
## Cohen d statistic of difference between two means
##    lower effect upper
## bp -0.98  -0.47  0.04
## 
## Multivariate (Mahalanobis) distance between groups
## [1] 0.47
## r equivalent of difference between two means
##    bp 
## -0.23</code></pre>
<p>Finally, we can apply <span class="math inline">\(d\)</span> to computing the statistical power:</p>
<pre class="r"><code># Power analysis using previous information
pwr::pwr.t.test(n=30, d=d$cohen.d[[2]], sig.level=0.05, type=&quot;paired&quot;)</code></pre>
<pre><code>## 
##      Paired t test power calculation 
## 
##               n = 30
##               d = 0.472
##       sig.level = 0.05
##           power = 0.704
##     alternative = two.sided
## 
## NOTE: n is number of *pairs*</code></pre>
</div>
